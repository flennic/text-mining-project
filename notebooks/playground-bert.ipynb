{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme.txt  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../src/data/original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p-bert_p-200'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = np.array([0.85, 0.1, 0.05])\n",
    "indicator = \"bert\"\n",
    "padding = \"200\"\n",
    "file_suffix = \"p-{}_p-{}\".format(indicator, padding)\n",
    "file_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_path =  u\"../src/data/original/train.csv\"\n",
    "orig_test_path = u\"../src/data/original/test.csv\"\n",
    "prep_train_path =  u\"../src/data/processed/train_{}_s{}.csv\".format(file_suffix, str(splits[0]))\n",
    "prep_val_path =  u\"../src/data/processed/val_{}_s{}.csv\".format(file_suffix, str(splits[1]))\n",
    "prep_test_path =  u\"../src/data/processed/test_{}_s{}.csv\".format(file_suffix, str(splits[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 s, sys: 2.16 s, total: 27.9 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(orig_train_path, header=None)\n",
    "test = pd.read_csv(orig_test_path, header=None)\n",
    "\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "del train, test\n",
    "\n",
    "data.columns = [\"label\", \"title\", \"review\"]\n",
    "data.drop(columns=['title'], inplace=True)\n",
    "data[\"label\"] = data[\"label\"] - 1\n",
    "data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "train, val, test = np.array_split(data, (splits[:-1].cumsum() * len(data)).astype(int))\n",
    "\n",
    "del data\n",
    "del train, val\n",
    "\n",
    "#train = train.values.tolist()\n",
    "#val = val.values.tolist()\n",
    "test = test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 'A very unexpected continuation of the first book, but with the same emotional feel and realism of the times and hearts of the characters. It has many new unexpected turns, with lots of suspense, but leaves you completely satisfied with how everything ties together in the end. This was better than the first book in the area of sensuality, as it was not completely focused on it, this time. In my view it was a more balanced look at life. I was a little disappointed with some characters left hanging at the end, but overall it was a well written story as part of a series.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test[0]\n",
    "tokenizerBert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "embedding_model = BertModel.from_pretrained('bert-base-uncased').cuda()\n",
    "unk_token = tokenizerBert._unk_token\n",
    "pad_token = tokenizerBert._pad_token\n",
    "padding = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very unexpected continuation of the first book, but with the same emotional feel and realism of the times and hearts of the characters. It has many new unexpected turns, with lots of suspense, but leaves you completely satisfied with how everything ties together in the end. This was better than the first book in the area of sensuality, as it was not completely focused on it, this time. In my view it was a more balanced look at life. I was a little disappointed with some characters left hanging at the end, but overall it was a well written story as part of a series.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 594 ms, sys: 0 ns, total: 594 ms\n",
      "Wall time: 592 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Tokenize\n",
    "batch = []\n",
    "\n",
    "for i in range(256):\n",
    "    batch.append(tokenizerBert.encode(sample[1], add_special_tokens=False, max_length=padding, pad_to_max_length=True))\n",
    "\n",
    "#sentence = tokenizer.encode(sample[1], add_special_tokens=False, max_length=padding, pad_to_max_length=True)\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gpu = torch.LongTensor(batch).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 200])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 ms, sys: 20.2 ms, total: 234 ms\n",
      "Wall time: 233 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    res = embedding_model(batch_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = res[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 200, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(embeddings, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del res\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batchAsList = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(batchAsList[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_out.dat\", \"ab\") as out_file:\n",
    "    for entry in batchAsList:\n",
    "        X = np.array(entry)\n",
    "        np.savetxt(out_file, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np        \n",
    "f=open('asd.dat','ab')\n",
    "for iind in range(4):\n",
    "    a=np.random.rand(10,10)\n",
    "    np.savetxt(f,a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row, padding=200,\n",
    "               tokenizer=tokenizerBert,\n",
    "               embedder=embedding_model,\n",
    "               unk_token=tokenizerBert._unk_token,\n",
    "               pad_token=tokenizerBert._pad_token):\n",
    "\n",
    "    # row = [label, review]\n",
    "    \n",
    "    # Tokenize, Vectorize and Pad\n",
    "    sentence_as_int = tokenizer.encode(row[1], add_special_tokens=False, max_length=padding, pad_to_max_length=True)\n",
    "\n",
    "    # X, Y\n",
    "    return sentence_as_int, row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cores = max(1, round(mp.cpu_count() / 2))\n",
    "print(cores)\n",
    "pool = mp.Pool(cores)\n",
    "\n",
    "# Parallelizing, will work as long as the processing is not too fast and fillst the memory :o\n",
    "processed_test = pool.imap(preprocess, test)\n",
    "\n",
    "with open(prep_test_path, \"w\") as out_file:\n",
    "    for X, Y in processed_test:\n",
    "        stringified = [str(entry) for entry in [Y] + X]\n",
    "        out_file.write(\",\".join(stringified) + \"\\n\")\n",
    "    \n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "del test, processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
