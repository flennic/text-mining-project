{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = u\"src/data/processed/train.mini.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in word vectors. Reduced to 500k due to RAM limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 776 ms, total: 16 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim\n",
    "embedding_model = gensim.models.KeyedVectors.load_word2vec_format('src/data/embeddings/GoogleNews-vectors-negative300.bin', binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset for the Amazon reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class AmazonReviewDataset(Dataset):\n",
    "    def __init__(self, path, embedding_model, padding=200, oov=\"<oov>\"):\n",
    "        \n",
    "        tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "        \n",
    "        self.samples = []\n",
    "        self.embedding = embedding_model\n",
    "        \n",
    "        # Load all the data\n",
    "        data = pd.read_csv(path)\n",
    "                \n",
    "        # Tokenize, pad and vectorize each review\n",
    "        for index, row in data.iterrows():\n",
    "            \n",
    "            # Tokenize\n",
    "            sentence = [token.lemma_ for token in tokenizer(row[\"review\"])]\n",
    "            \n",
    "            # Pad\n",
    "            sentence = sentence[:padding] + [oov]*(padding - len(sentence))\n",
    "            \n",
    "            self.samples.append([row[\"id\"], row[\"label\"], row[\"alpha\"]] + sentence)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 23s, sys: 248 ms, total: 3min 24s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = AmazonReviewDataset(path, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataLoader as well, using a custom collate function for creating the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def row2tensors(sentence):\n",
    "    mean_vec = np.mean([embedding_model[word] for word in sentence[3:] if embedding_model.vocab.get(word) is not None], axis=0).flatten()\n",
    "    mean_word = embedding_model.similar_by_vector(mean_vec, topn=1)[0][0]\n",
    "    filled_sentence = [word if embedding_model.vocab.get(word[0]) is not None else (mean_word,) for word in sentence[3:]]\n",
    "    sentence_as_int = [embedding_model.vocab.get(word[0]).index for word in filled_sentence]\n",
    "    return sentence_as_int, sentence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch2tensor(batch):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for row in batch:\n",
    "        x, y = row2tensors(row)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return torch.LongTensor(X), torch.LongTensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, collate_fn=batch2tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 ms, sys: 21 Âµs, total: 11.6 ms\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_dash, Y_dash = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dash = X_dash.cuda()\n",
    "Y_dash = Y_dash.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dash.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dash.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, word_embeddings, embedding_size=300, padding=200, category_amount=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Predefined word embeddings\n",
    "        self.embedding = nn.Embedding.from_pretrained(word_embeddings)\n",
    "        \n",
    "\n",
    "        self.l1 = nn.Linear(embedding_size * padding, 1024)\n",
    "        self.l2 = nn.Linear(1024, 128)\n",
    "        self.l3 = nn.Linear(128, category_amount)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.l1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(torch.FloatTensor(embedding_model.vectors)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (embedding): Embedding(500000, 300)\n",
       "  (l1): Linear(in_features=60000, out_features=1024, bias=True)\n",
       "  (l2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (l3): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_dash).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_dash)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASAklEQVR4nO3df6hfd33H8efLW1OHP7ZqL2xLUhM1HUbdWrhGQXSgrca5Jf5RMQ5HhUJwNOisY1aUihFBK6j7I2KDholbF6vd4CKR0PlriKu9t7arS7robXTmEqFX0+lEbb3xvT/uUb7efpN7bu6v9nOfD/iS8/l1vu9DyOuenO/5npuqQpLUriesdQGSpJVl0EtS4wx6SWqcQS9JjTPoJalxF611AfNdeumltWXLlrUuQ5IeV+6+++4fVtXosLFeQZ9kJ/D3wAjwiar6wDnmXQN8FnhhVU12fe8ErgPOAm+pqqPne68tW7YwOTnZpyxJUifJ/5xrbMGgTzICHACuBqaBiSTjVXV83rynAm8BvjHQtx3YAzwP+EPg35JcXlVnL+RAJEmL1+ca/Q5gqqpOVtUjwGFg95B57wNuBn4x0LcbOFxVD1fVd4Gpbn+SpFXSJ+g3AqcG2tNd328kuRLYXFWfX+zabv3eJJNJJmdmZnoVLknqp0/QZ0jfb56bkOQJwEeAty927W86qg5W1VhVjY2ODv0sQZJ0gfp8GDsNbB5obwJOD7SfCjwf+EoSgN8HxpPs6rFWkrTC+pzRTwDbkmxNsoG5D1fHfz1YVT+uqkuraktVbQHuBHZ1d92MA3uSXJxkK7ANuGvZj0KSdE4LntFX1WySfcBR5m6vPFRVx5LsByaravw8a48luQ04DswC13vHjSStrjzWHlM8NjZW3kcvSYuT5O6qGhs25iMQJKlxj7lHIOjCfeSOb691CcvmbVdfvtYlSM3wjF6SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1LheQZ9kZ5ITSaaS3Dhk/M1JvpXk3iRfS7K969+S5Odd/71JPr7cByBJOr8Ff8NUkhHgAHA1MA1MJBmvquMD026tqo9383cBHwZ2dmMPVNUVy1u2JKmvPmf0O4CpqjpZVY8Ah4HdgxOq6icDzScDj63fOC5J61ifoN8InBpoT3d9vyXJ9UkeAG4G3jIwtDXJPUm+muSlw94gyd4kk0kmZ2ZmFlG+JGkhfYI+Q/oedcZeVQeq6tnAO4B3d90/AC6rqiuBG4BbkzxtyNqDVTVWVWOjo6P9q5ckLahP0E8Dmwfam4DT55l/GHgtQFU9XFU/6rbvBh4ALr+wUiVJF6JP0E8A25JsTbIB2AOMD05Ism2g+RrgO13/aPdhLkmeBWwDTi5H4ZKkfha866aqZpPsA44CI8ChqjqWZD8wWVXjwL4kVwG/BB4Cru2WvwzYn2QWOAu8uarOrMSBSJKGWzDoAarqCHBkXt9NA9tvPce624Hbl1KgJGlp/GasJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Qr6JDuTnEgyleTGIeNvTvKtJPcm+VqS7QNj7+zWnUjyquUsXpK0sAWDPskIcAB4NbAdeMNgkHduraoXVNUVwM3Ah7u124E9wPOAncDHuv1JklZJnzP6HcBUVZ2sqkeAw8DuwQlV9ZOB5pOB6rZ3A4er6uGq+i4w1e1PkrRKLuoxZyNwaqA9Dbxo/qQk1wM3ABuAlw+svXPe2o1D1u4F9gJcdtllfeqWJPXU54w+Q/rqUR1VB6rq2cA7gHcvcu3BqhqrqrHR0dEeJUmS+uoT9NPA5oH2JuD0eeYfBl57gWslScusT9BPANuSbE2ygbkPV8cHJyTZNtB8DfCdbnsc2JPk4iRbgW3AXUsvW5LU14LX6KtqNsk+4CgwAhyqqmNJ9gOTVTUO7EtyFfBL4CHg2m7tsSS3AceBWeD6qjq7QsciSRqiz4exVNUR4Mi8vpsGtt96nrXvB95/oQVKkpbGb8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS43oFfZKdSU4kmUpy45DxG5IcT3Jfki8meebA2Nkk93av8flrJUkra8FfJZhkBDgAXA1MAxNJxqvq+MC0e4CxqvpZkr8GbgZe3439vKquWOa6JUk99Tmj3wFMVdXJqnoEOAzsHpxQVV+uqp91zTuBTctbpiTpQvUJ+o3AqYH2dNd3LtcBXxhoPynJZJI7k7x22IIke7s5kzMzMz1KkiT1teClGyBD+mroxOSNwBjwpwPdl1XV6STPAr6U5FtV9cBv7azqIHAQYGxsbOi+JUkXps8Z/TSweaC9CTg9f1KSq4B3Abuq6uFf91fV6e7Pk8BXgCuXUK8kaZH6BP0EsC3J1iQbgD3Ab909k+RK4BbmQv7Bgf5LklzcbV8KvAQY/BBXkrTCFrx0U1WzSfYBR4ER4FBVHUuyH5isqnHgQ8BTgM8mAfh+Ve0CngvckuRXzP1Q+cC8u3UkSSuszzV6quoIcGRe300D21edY93XgRcspUBJ0tL4zVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY3rFfRJdiY5kWQqyY1Dxm9IcjzJfUm+mOSZA2PXJvlO97p2OYuXJC1swaBPMgIcAF4NbAfekGT7vGn3AGNV9cfA54Cbu7VPB94DvAjYAbwnySXLV74kaSF9zuh3AFNVdbKqHgEOA7sHJ1TVl6vqZ13zTmBTt/0q4I6qOlNVDwF3ADuXp3RJUh99gn4jcGqgPd31nct1wBcWszbJ3iSTSSZnZmZ6lCRJ6qtP0GdIXw2dmLwRGAM+tJi1VXWwqsaqamx0dLRHSZKkvvoE/TSweaC9CTg9f1KSq4B3Abuq6uHFrJUkrZw+QT8BbEuyNckGYA8wPjghyZXALcyF/IMDQ0eBVya5pPsQ9pVdnyRplVy00ISqmk2yj7mAHgEOVdWxJPuByaoaZ+5SzVOAzyYB+H5V7aqqM0nex9wPC4D9VXVmRY5EkjTUgkEPUFVHgCPz+m4a2L7qPGsPAYcutEBJ0tL4zVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuN6/eIRSXqs+sgd317rEpbN266+fEX221zQt/KXvlJ/4ZLWn16XbpLsTHIiyVSSG4eMvyzJN5PMJrlm3tjZJPd2r/H5ayVJK2vBM/okI8AB4GpgGphIMl5VxwemfR94E/C3Q3bx86q6Yhlqlc6plf/Jgf+b0/Lrc+lmBzBVVScBkhwGdgO/Cfqq+l439qsVqFGStAR9Lt1sBE4NtKe7vr6elGQyyZ1JXjtsQpK93ZzJmZmZRexakrSQPkGfIX21iPe4rKrGgL8EPprk2Y/aWdXBqhqrqrHR0dFF7FqStJA+QT8NbB5obwJO932Dqjrd/XkS+Apw5SLqkyQtUZ+gnwC2JdmaZAOwB+h190ySS5Jc3G1fCryEgWv7kqSVt+CHsVU1m2QfcBQYAQ5V1bEk+4HJqhpP8kLgX4FLgL9I8t6qeh7wXOCW7kPaJwAfmHe3jqRl4F1HOp9eX5iqqiPAkXl9Nw1sTzB3SWf+uq8DL1hijZKkJfBZN5LUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4XkGfZGeSE0mmktw4ZPxlSb6ZZDbJNfPGrk3yne517XIVLknqZ8GgTzICHABeDWwH3pBk+7xp3wfeBNw6b+3TgfcALwJ2AO9JcsnSy5Yk9dXnjH4HMFVVJ6vqEeAwsHtwQlV9r6ruA341b+2rgDuq6kxVPQTcAexchrolST31CfqNwKmB9nTX10evtUn2JplMMjkzM9Nz15KkPvoEfYb0Vc/991pbVQeraqyqxkZHR3vuWpLUR5+gnwY2D7Q3Aad77n8payVJy6BP0E8A25JsTbIB2AOM99z/UeCVSS7pPoR9ZdcnSVolCwZ9Vc0C+5gL6PuB26rqWJL9SXYBJHlhkmngdcAtSY51a88A72Puh8UEsL/rkyStkov6TKqqI8CReX03DWxPMHdZZtjaQ8ChJdQoSVoCvxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxvYI+yc4kJ5JMJblxyPjFST7TjX8jyZauf0uSnye5t3t9fHnLlyQtZMHfGZtkBDgAXA1MAxNJxqvq+MC064CHquo5SfYAHwRe3409UFVXLHPdkqSe+pzR7wCmqupkVT0CHAZ2z5uzG/hUt/054BVJsnxlSpIuVJ+g3wicGmhPd31D51TVLPBj4Bnd2NYk9yT5apKXDnuDJHuTTCaZnJmZWdQBSJLOr0/QDzszr55zfgBcVlVXAjcAtyZ52qMmVh2sqrGqGhsdHe1RkiSprz5BPw1sHmhvAk6fa06Si4DfBc5U1cNV9SOAqrobeAC4fKlFS5L66xP0E8C2JFuTbAD2AOPz5owD13bb1wBfqqpKMtp9mEuSZwHbgJPLU7okqY8F77qpqtkk+4CjwAhwqKqOJdkPTFbVOPBJ4NNJpoAzzP0wAHgZsD/JLHAWeHNVnVmJA5EkDbdg0ANU1RHgyLy+mwa2fwG8bsi624Hbl1ijJGkJ/GasJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TG9Qr6JDuTnEgyleTGIeMXJ/lMN/6NJFsGxt7Z9Z9I8qrlK12S1MeCQZ9kBDgAvBrYDrwhyfZ5064DHqqq5wAfAT7Yrd3O3C8Kfx6wE/hYtz9J0irpc0a/A5iqqpNV9QhwGNg9b85u4FPd9ueAVyRJ13+4qh6uqu8CU93+JEmr5KIeczYCpwba08CLzjWnqmaT/Bh4Rtd/57y1G+e/QZK9wN6u+dMkJ3pVv3YuBX64km9ww0rufGlW/NhhfR//ej52WN/Hv8Rjf+a5BvoEfYb0Vc85fdZSVQeBgz1qeUxIMllVY2tdx1pYz8cO6/v41/Oxw+P7+PtcupkGNg+0NwGnzzUnyUXA7wJneq6VJK2gPkE/AWxLsjXJBuY+XB2fN2ccuLbbvgb4UlVV17+nuytnK7ANuGt5Spck9bHgpZvumvs+4CgwAhyqqmNJ9gOTVTUOfBL4dJIp5s7k93RrjyW5DTgOzALXV9XZFTqW1fS4ucy0AtbzscP6Pv71fOzwOD7+zJ14S5Ja5TdjJalxBr0kNc6gX6SFHgfRqiSHkjyY5L/WupbVlmRzki8nuT/JsSRvXeuaVlOSJyW5K8l/dsf/3rWuabUlGUlyT5LPr3UtF8KgX4Sej4No1T8w9xiL9WgWeHtVPRd4MXD9Ovp7B3gYeHlV/QlwBbAzyYvXuKbV9lbg/rUu4kIZ9IvT53EQTaqqf2fujqp1p6p+UFXf7Lb/j7l/8I/6hneras5Pu+YTu9e6uYsjySbgNcAn1rqWC2XQL86wx0Gsm3/wgu7JrFcC31jbSlZXd+niXuBB4I6qWk/H/1Hg74BfrXUhF8qgX5xej3RQm5I8Bbgd+Juq+sla17OaqupsVV3B3LfbdyR5/lrXtBqS/DnwYFXdvda1LIVBvzg+0mGdSvJE5kL+n6rqX9a6nrVSVf8LfIX183nNS4BdSb7H3KXalyf5x7UtafEM+sXp8zgINaZ75PYngfur6sNrXc9qSzKa5Pe67d8BrgL+e22rWh1V9c6q2lRVW5j79/6lqnrjGpe1aAb9IlTVLPDrx0HcD9xWVcfWtqrVkeSfgf8A/ijJdJLr1rqmVfQS4K+YO5u7t3v92VoXtYr+APhykvuYO9m5o6oel7cZrlc+AkGSGucZvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9Jjft/hc9N6UzHUoAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(0,5), np.exp(model(X_dash).detach().cpu().numpy()[0]), alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, nesterov=False, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.6203687716596804\n",
      "Training loss: 1.607266703733621\n",
      "Training loss: 1.5878852346834664\n",
      "Training loss: 1.5747774035785906\n",
      "Training loss: 1.5690410323798085\n",
      "Training loss: 1.5603210324296555\n",
      "Training loss: 1.5520700726646204\n",
      "Training loss: 1.5390696205651035\n",
      "Training loss: 1.5247955885938942\n",
      "Training loss: 1.5087085448134059\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for X, Y in dataloader:\n",
    "        X = X.cuda()\n",
    "        Y = Y.cuda()\n",
    "    \n",
    "        # Reset Gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(X)\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(0,5), np.exp(model(X_dash).detach().cpu().numpy()[0]), alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dash[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, yt = row2tensors(dataset[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = torch.LongTensor(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = XT.view(1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5978, -1.1697, -1.3130, -2.0219, -2.4559]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(XT.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(0,5), np.exp(model(XT.cuda()).detach().cpu().numpy()[0]), alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/flennic/git/text-mining-project/src/data/processed/train.csv\", header=None)\n",
    "test = pd.read_csv(\"/home/flennic/git/text-mining-project/src/data/processed/test.csv\", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids1 = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\".lower(), add_special_tokens=True)).unsqueeze(0).to('cuda')  # Batch size 1\n",
    "input_ids2 = torch.tensor(tokenizer.encode(\"Hello, my cat is ugly\".lower(), add_special_tokens=True)).unsqueeze(0).to('cuda')  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat((input_ids1, input_ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([0, 1]).unsqueeze(0).to('cuda')   # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logits = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(logits.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0).to('cuda')  # Batch size 1\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"Hello, my dog is cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"[CLS]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0][0, 0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (\"a\", \"b\", \"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (1, 2) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('src/data/embeddings/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"hello\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
